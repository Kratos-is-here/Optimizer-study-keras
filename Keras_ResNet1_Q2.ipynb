{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Keras-ResNet1 / Q2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kratos-is-here/Optimizer-study-keras/blob/main/Keras_ResNet1_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-5hcTHmGgeQ"
      },
      "source": [
        "# Residual Networks\n",
        "\n",
        "Welcome to another tutorial! Now we will learn how to build very deep convolutional networks, using Residual Networks (ResNets). \n",
        "\n",
        "**In this assignment, we will:**\n",
        "- Implement the basic building blocks of ResNets. \n",
        "- Put together these building blocks to implement and train a state-of-the-art neural network for image classification. \n",
        "\n",
        "Let's run the cell below to load the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t8YHkWuGqew",
        "outputId": "b387902e-5dd0-4583-d19c-467c738ddc5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIjpjI2kGgeX"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import cv2\n",
        "import numpy as np\n",
        "import copy\n",
        "from numpy.random import permutation\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from keras import layers\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "# %tensorflow_version 1.15.2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD4xuu7UGgeY"
      },
      "source": [
        "ROWS = 64\n",
        "COLS = 64\n",
        "CHANNELS = 3\n",
        "CLASSES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF67Gi-KGgeY"
      },
      "source": [
        "def read_image(file_path):\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "def prepare_data(images):\n",
        "    m = len(images)\n",
        "    X = np.zeros((m, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "    y = np.zeros((1, m), dtype=np.uint8)\n",
        "    for i, image_file in enumerate(images):\n",
        "        X[i,:] = read_image(image_file)\n",
        "        if 'dog' in image_file.lower():\n",
        "            y[0, i] = 1\n",
        "        elif 'cat' in image_file.lower():\n",
        "            y[0, i] = 0\n",
        "    return X, y\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH8xxLMLGgeY"
      },
      "source": [
        "Run the following code to normalize the dataset and learn about its shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "IScaWS6SGgeZ",
        "outputId": "462a85d9-42c9-481d-edaa-8e755824d835"
      },
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/Colab Notebooks/data set/train_data/'\n",
        "TEST_DIR = '/content/drive/MyDrive/Colab Notebooks/data set/Test_data/'\n",
        "\n",
        "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
        "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
        "\n",
        "train_set_x, train_set_y = prepare_data(train_images)\n",
        "test_set_x, test_set_y = prepare_data(test_images)\n",
        "\n",
        "X_train = train_set_x/255\n",
        "X_test = test_set_x/255\n",
        "\n",
        "Y_train = convert_to_one_hot(train_set_y, CLASSES).T\n",
        "Y_test = convert_to_one_hot(test_set_y, CLASSES).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c1abc83b997f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mTEST_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_set_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_set_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ec93c9d83113>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'dog'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ec93c9d83113>\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROWS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH8sYg4CGgeZ"
      },
      "source": [
        "print (\"number of training examples =\", X_train.shape[0])\n",
        "print (\"number of test examples =\", X_test.shape[0])\n",
        "print (\"X_train shape:\", X_train.shape)\n",
        "print (\"Y_train shape:\", Y_train.shape)\n",
        "print (\"X_test shape:\", X_test.shape)\n",
        "print (\"Y_test shape:\", Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWqj-dU6Ggea"
      },
      "source": [
        "## 2 - Building a Residual Network\n",
        "\n",
        "In ResNets, a \"shortcut\" or a \"skip connection\" allows the gradient to be directly backpropagated to earlier layers:  \n",
        "\n",
        "<img src=\"images/skip_connection.png\" style=\"width:650px;height:200px;\">\n",
        "\n",
        "Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are same or different. We are going to implement both of them.\n",
        "\n",
        "#### Why do Skip Connections work?\n",
        "- They mitigate the problem of vanishing gradient by allowing this alternate shortcut path for gradient to flow through\n",
        "- They allow the model to learn an identity function which ensures that the higher layer will perform at least as good as the lower layer, and not worse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IIJKJR-Ggeb"
      },
      "source": [
        "### 2.1 - The identity block\n",
        "\n",
        "We'll implement identity block, in which the skip connection \"skips over\" 3 hidden layers rather than 2 layers. It looks like this: \n",
        "\n",
        "<img src=\"images/Identity_block2.png\" style=\"width:650px;height:150px;\">\n",
        "\n",
        "\n",
        "**Arguments**:<br>\n",
        "    X - input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)<br>\n",
        "    f - integer, specifying the shape of the middle CONV's window for the main path<br>\n",
        "    filters - python list of integers, defining the number of filters in the CONV layers of the main path<br>\n",
        "    stage - integer, used to name the layers, depending on their position in the network<br>\n",
        "    block - string/character, used to name the layers, depending on their position in the network<br>\n",
        "\n",
        "**Returns**:<br>\n",
        "    X - output of the identity block, tensor of shape (n_H, n_W, n_C)<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IlATsffGgeb"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. We'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HArHK9JGgec"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as test:\n",
        "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
        "    X = np.random.randn(3, 4, 4, 6)\n",
        "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
        "    test.run(tf.global_variables_initializer())\n",
        "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
        "    print(\"out = \", out[0][1][1][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7NcIcJDGgec"
      },
      "source": [
        "## 2.2 - The convolutional block\n",
        "\n",
        "The ResNet \"convolutional block\" is the other type of block: \n",
        "\n",
        "<img src=\"images/Identity_block3.png\" style=\"width:650px;height:150px;\">\n",
        "\n",
        "    \n",
        "**Arguments**:<br>\n",
        "    X - input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)<br>\n",
        "    f - integer, specifying the shape of the middle CONV's window for the main path<br>\n",
        "    filters - python list of integers, defining the number of filters in the CONV layers of the main path<br>\n",
        "    stage - integer, used to name the layers, depending on their position in the network<br>\n",
        "    block - string/character, used to name the layers, depending on their position in the network<br>\n",
        "    s - Integer, specifying the stride to be used<br>\n",
        "\n",
        "**Returns**:<br>\n",
        "    X - output of the convolutional block, tensor of shape (n_H, n_W, n_C)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pHufXLeGged"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    \n",
        "    ##### SHORTCUT PATH ####\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysGlMnIZGgee"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as test:\n",
        "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
        "    X = np.random.randn(3, 4, 4, 6)\n",
        "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
        "    test.run(tf.global_variables_initializer())\n",
        "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
        "    print(\"out = \",out[0][1][1][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa-cZEqDGgee"
      },
      "source": [
        "## 3 - Building our first ResNet model (50 layers)\n",
        "\n",
        "We now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. \"ID BLOCK\" in the diagram stands for \"Identity block,\" and \"ID BLOCK x3\" means you should stack 3 identity blocks together.\n",
        "\n",
        "<img src=\"images/ResNet-50.png\" style=\"width:850px;height:150px;\">\n",
        "\n",
        "The details of this ResNet-50 model are:\n",
        "- Zero-padding pads the input with a pad of (3,3)\n",
        "- Stage 1:\n",
        "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is \"conv1\".\n",
        "    - BatchNorm is applied to the channels axis of the input.\n",
        "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
        "- Stage 2:\n",
        "    - The convolutional block uses three set of filters of size [64,64,256], \"f\" is 3, \"s\" is 1 and the block is \"a\".\n",
        "    - The 2 identity blocks use three set of filters of size [64,64,256], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
        "- Stage 3:\n",
        "    - The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "    - The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
        "- Stage 4:\n",
        "    - The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "    - The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
        "- Stage 5:\n",
        "    - The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
        "    - The 2 identity blocks use three set of filters of size [512, 512, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
        "- The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
        "- The flatten doesn't have any hyperparameters or name.\n",
        "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation. Its name should be `'fc' + str(classes)`.\n",
        "\n",
        "So we will implement the ResNet with 50 layers described in the figure above into following architecture:<br>\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "**Arguments**:<br>\n",
        "    input_shape - shape of the images of the dataset<br>\n",
        "    classes - integer, number of classes<br>\n",
        "\n",
        "**Returns**:<br>\n",
        "    model - a Model() instance in Keras<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ4oqhIjGgee"
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 2):   \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL.\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIL-7e-2Ggef"
      },
      "source": [
        "Run the following code to build the model's graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvZAg65mGgef"
      },
      "source": [
        "model = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_BpD7OJGgeg"
      },
      "source": [
        "Now we need to configure the learning process by compiling the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG6npvP6Ggeg"
      },
      "source": [
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer='RectifiedAdam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(optimizer='Adadelta, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(optimizer='Adagrad', loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(optimizer='Adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(optimizer='Nadam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MSAcqqyGgeg"
      },
      "source": [
        "The model is now ready to be trained. Run the following cell to train your model on 100 epochs with a batch size of 64:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XPZVsyVGgeg"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs = 100, batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wz3OFpHGgeh"
      },
      "source": [
        "Let's see how this model performs on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4MiVDnkGgeh"
      },
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHgjImUGGgej"
      },
      "source": [
        "We can also print a summary of our model by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob5uY14kGgej"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmeq-nfCGgek"
      },
      "source": [
        "For future use we can save our model to file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaelAytwGgek"
      },
      "source": [
        "model.save('ResNet50.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBpovMKjGgek"
      },
      "source": [
        "Finally, we can run the code below to visualize our ResNet50:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysdtNzydGgek"
      },
      "source": [
        "plot_model(model, to_file='model.png')\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O560tHUpGgek"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}